{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3ff81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from neuralop.data.datasets.custom_darcy import CustomDarcyDataset, load_darcy_flow\n",
    "import matplotlib.pyplot as plt\n",
    "from neuralop.models import TFNO\n",
    "from neuralop import Trainer\n",
    "from neuralop.training import AdamW\n",
    "from neuralop.utils import count_model_params\n",
    "from neuralop import LpLoss, H1Loss\n",
    "from copy import deepcopy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a3476cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haltmayermarc/Samsung_new/neuraloperator/neuralop/data/datasets/pt_dataset.py:99: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test db for resolution 1024 with 50 samples \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haltmayermarc/Samsung_new/neuraloperator/neuralop/data/datasets/pt_dataset.py:196: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(Path(root_dir).joinpath(f\"{dataset_name}_test_{res}.pt\").as_posix())\n"
     ]
    }
   ],
   "source": [
    "resolution = 1024\n",
    "num_levels = 3\n",
    "\n",
    "train_loader_list, test_loader_list, data_processor_list = load_darcy_flow(\n",
    "    root_dir=\"data\",\n",
    "    dataset_name=\"darcy_ZD_PWC\",\n",
    "    n_train=1000,\n",
    "    n_tests=[50],\n",
    "    batch_size=20,\n",
    "    test_batch_sizes=[50],\n",
    "    train_resolution=resolution,\n",
    "    test_resolutions=[resolution],\n",
    "    decompose_multigrid=True,\n",
    "    L=num_levels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04a94ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 4, 128, 128]),\n",
       " torch.Size([1000, 1, 128, 128]),\n",
       " tensor(0.),\n",
       " tensor(12.),\n",
       " tensor(0., dtype=torch.float64),\n",
       " tensor(0.0059, dtype=torch.float64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader_list[0].dataset.x.shape, train_loader_list[0].dataset.y.shape, train_loader_list[0].dataset.x.min(), train_loader_list[0].dataset.x.max(), train_loader_list[0].dataset.y.min(), train_loader_list[0].dataset.y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "689453a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "l2loss = LpLoss(d=2, p=2)\n",
    "h1loss = H1Loss(d=2)\n",
    "train_loss = h1loss\n",
    "eval_losses={'h1': h1loss, 'l2': l2loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57d90216",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_570897/1713088587.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 64 models\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"./experiments/tfno_models\"\n",
    "loaded_models = []\n",
    "\n",
    "for i in range(len(data_processor_list)):  \n",
    "    model_path = os.path.join(save_dir, f\"tfno_model_{i}.pth\")\n",
    "\n",
    "    model = TFNO(\n",
    "        n_modes=(16, 16),\n",
    "        hidden_channels=64,\n",
    "        in_channels=num_levels+1,   # same as training\n",
    "        out_channels=1,\n",
    "        factorization='tucker',\n",
    "        implementation='factorized',\n",
    "        rank=0.05\n",
    "    ).to(device)\n",
    "\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    #model.eval()  # set to evaluation mode\n",
    "    loaded_models.append(model)\n",
    "\n",
    "print(f\"Loaded {len(loaded_models)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "164f6341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9310533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_predictions(models, test_loader_list, data_processor_list,\n",
    "                       global_res, device):\n",
    "    # Assume all models have the same local resolution\n",
    "    local_res = models[0].out_channels_size if hasattr(models[0], \"out_channels_size\") else \\\n",
    "                next(iter(test_loader_list[0].values())).dataset.y.shape[-1]\n",
    "\n",
    "    num_per_axis = global_res // local_res\n",
    "    num_models = num_per_axis ** 2\n",
    "\n",
    "    full_output = None\n",
    "    batch_size = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, model in enumerate(models):\n",
    "            dp = data_processor_list[idx]\n",
    "            loader = test_loader_list[idx][global_res]\n",
    "\n",
    "            xb = loader.dataset.x.to(device)   # [batch, in_channels, local_res, local_res]\n",
    "            y_pred = model(xb)\n",
    "            y_pred = dp.out_normalizer.inverse_transform(y_pred)\n",
    "\n",
    "            if full_output is None:\n",
    "                batch_size = y_pred.shape[0]\n",
    "                full_output = torch.zeros(batch_size, 1, global_res, global_res, device=device)\n",
    "\n",
    "            # Compute tile position\n",
    "            i = idx // num_per_axis  # row index\n",
    "            j = idx % num_per_axis   # col index\n",
    "            r_start, r_end = i * local_res, (i + 1) * local_res\n",
    "            c_start, c_end = j * local_res, (j + 1) * local_res\n",
    "\n",
    "            full_output[:, :, r_start:r_end, c_start:c_end] = y_pred\n",
    "\n",
    "    return full_output\n",
    "\n",
    "def plot_comparison(y_full, y_reconstructed):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    im0 = axs[0].imshow(y_full.squeeze().cpu(), cmap='viridis')\n",
    "    axs[0].set_title(\"Original Solution\")\n",
    "    fig.colorbar(im0, ax=axs[0])\n",
    "    \"\"\"\n",
    "    im1 = axs[1].imshow(y_tfno.squeeze().cpu(), cmap='viridis')\n",
    "    axs[1].set_title(\"Full TFNO Prediction\")\n",
    "    fig.colorbar(im1, ax=axs[1])12\n",
    "    \"\"\"\n",
    "    \n",
    "    im2 = axs[1].imshow(y_reconstructed.squeeze().cpu(), cmap='viridis')\n",
    "    axs[2].set_title(\"Reconstructed from Subdomains\")\n",
    "    fig.colorbar(im2, ax=axs[2])\n",
    "\n",
    "    im3 = axs[2].imshow((y_reconstructed - y_full).abs().squeeze().cpu(), cmap='inferno')\n",
    "    axs[3].set_title(\"Reconstruction Error\")\n",
    "    fig.colorbar(im3, ax=axs[3])\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0884be8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haltmayermarc/Samsung_new/neuraloperator/neuralop/data/datasets/pt_dataset.py:99: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test db for resolution 1024 with 50 samples \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haltmayermarc/Samsung_new/neuraloperator/neuralop/data/datasets/pt_dataset.py:196: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(Path(root_dir).joinpath(f\"{dataset_name}_test_{res}.pt\").as_posix())\n"
     ]
    }
   ],
   "source": [
    "resolution = 1024\n",
    "\n",
    "train_loader, test_loaders, data_processor = load_darcy_flow(\n",
    "    root_dir=\"./data/\",\n",
    "    dataset_name='darcy_ZD_PWC',\n",
    "    n_train=1000,\n",
    "    n_tests=[50],\n",
    "    batch_size=20,\n",
    "    test_batch_sizes=[50],\n",
    "    train_resolution=resolution,\n",
    "    test_resolutions=[resolution]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62eb590b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m random_index = np.random.randint(\u001b[32m0\u001b[39m, test_loaders[resolution].dataset.x.shape[\u001b[32m0\u001b[39m] - \u001b[32m1\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Reconstruct output from subdomains\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m y_reconstructed = \u001b[43mstitch_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_processor_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Get ground truth solution\u001b[39;00m\n\u001b[32m      7\u001b[39m y_full = test_loaders[resolution].dataset.y[random_index:random_index+\u001b[32m1\u001b[39m].to(device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mstitch_predictions\u001b[39m\u001b[34m(models, test_loader_list, data_processor_list, global_res, device)\u001b[39m\n\u001b[32m     18\u001b[39m xb = loader.dataset.x.to(device)   \u001b[38;5;66;03m# [batch, in_channels, local_res, local_res]\u001b[39;00m\n\u001b[32m     19\u001b[39m y_pred = model(xb)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m y_pred = \u001b[43mdp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mout_normalizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m full_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     23\u001b[39m     batch_size = y_pred.shape[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Samsung_new/neuraloperator/neuralop/data/transforms/normalizers.py:151\u001b[39m, in \u001b[36mUnitGaussianNormalizer.inverse_transform\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minverse_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m + \u001b[38;5;28mself\u001b[39m.mean\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cpu!"
     ]
    }
   ],
   "source": [
    "random_index = np.random.randint(0, test_loaders[resolution].dataset.x.shape[0] - 1)\n",
    "\n",
    "# Reconstruct output from subdomains\n",
    "y_reconstructed = stitch_predictions(loaded_models, test_loader_list, data_processor_list, resolution, device)\n",
    "\n",
    "# Get ground truth solution\n",
    "y_full = test_loaders[resolution].dataset.y[random_index:random_index+1].to(device)\n",
    "\n",
    "# Plot original, TFNO, subdomain reconstruction\n",
    "plot_comparison(y_full, y_reconstructed[random_index:random_index+1])\n",
    "\n",
    "print(f'L2 error (MG-TFNO) : {torch.norm(y_full - y_reconstructed[random_index:random_index+1]) / torch.norm(y_full)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d6fedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average L2 error (TFNO) : 0.08486156519743492\n",
      "Average L2 error (MG-TFNO) : 0.08247708511418811\n"
     ]
    }
   ],
   "source": [
    "tfno_error = 0\n",
    "mg_tfno_error = 0\n",
    "\n",
    "for idx in range(test_loaders[resolution].dataset.x.shape[0]):\n",
    "\n",
    "    # Reconstruct output from subdomains\n",
    "    y_reconstructed = stitch_predictions(loaded_models, test_loader_list, data_processor_list, resolution, device)\n",
    "\n",
    "    # Get ground truth solution\n",
    "    y_full = test_loaders[resolution].dataset.y[idx:idx+1].to(device)\n",
    "\n",
    "    mg_tfno_error += torch.norm(y_full - y_reconstructed[idx:idx+1]) / torch.norm(y_full)\n",
    "\n",
    "mg_tfno_error /= test_loaders[resolution].dataset.x.shape[0]\n",
    "\n",
    "print(f'Average L2 error (MG-TFNO) : {mg_tfno_error}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
